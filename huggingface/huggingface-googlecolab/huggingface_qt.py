# Specify UTF-8 encoding for the file to handle Unicode characters properly
# -*- coding: utf-8 -*-
# Docstring providing information about the file's origin and generation
"""Huggingface QT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bxyMr8PVqnB4904gGhT6WYU0w5TRYjPg
"""

# Comment explaining that the IPython magic is commented out for Python compatibility
# Commented out IPython magic to ensure Python compatibility.
# The pip install command for transformers library
# %pip install transformers

# Import the pipeline function from the transformers library to use pre-built models
from transformers import pipeline

# Create a sentiment analysis pipeline using the specified model for English text
classifier = pipeline(
    "sentiment-analysis",
    model="distilbert/distilbert-base-uncased-finetuned-sst-2-english")

# Commented out example of positive sentiment analysis
#response = classifier("I like Large Language models very much") # This is a positive sentiment
# Commented out print statement for the positive response
#print(response)

# Perform sentiment analysis on a negative sentiment text
response = classifier("I got irritate standing in line at airport") # This is a negative sentiment
# Print the sentiment analysis result
print(response)

# Create a translation pipeline from English to Hindi using the specified model
summerisator = pipeline("translation_en_to_hi", model="Helsinki-NLP/opus-mt-en-hi")
# Translate the given English text to Hindi
response = summerisator("I like Large Language models very much")
# Print the translation result
print(response )

# Create a text generation pipeline using the specified model
generator = pipeline("text-generation", model="Qwen/Qwen3-0.6B")
# Generate text based on the given prompt
response = generator("write the small story")

# Create another pipeline for text classification with the Qwen model, returning all scores
classifier = pipeline("text-classification", model="Qwen/Qwen3-0.6B", return_all_scores=True)
# Classify the sentiment of the text and return all scores
response = classifier("I like Large Language models very much")
# Print the classification result
print(response)


# Classifier 
# Initialize the zero-shot classification pipeline with the model
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

# Define your input text and candidate labels
input_text = "The national team's new coach announced his strategy for the upcoming world cup."
candidate_labels = ["sports", "Politics", "Technology"]

# Perform classification
result = classifier(input_text, candidate_labels)

# Print the results
print(result)

